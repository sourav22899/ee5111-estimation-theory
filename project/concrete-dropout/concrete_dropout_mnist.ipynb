{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "concrete_dropout_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9CBAIqPP8sU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "cd1c8be4-c58a-45d1-ba7c-79e664a7699c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 13 13:43:19 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWEkPMaeQDUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Lambda, Concatenate, Layer\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c36c2bFYQFQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8f98cee-fedd-4538-8c2f-c921742e2f98"
      },
      "source": [
        "class ConcreteDropout(Layer):\n",
        "    \"\"\"This wrapper allows to learn the dropout probability for any given input Dense layer.\n",
        "    ```python\n",
        "        # as the first layer in a model\n",
        "        model = Sequential()\n",
        "        model.add(ConcreteDropout(Dense(8), input_shape=(16)))\n",
        "        # now model.output_shape == (None, 8)\n",
        "        # subsequent layers: no need for input_shape\n",
        "        model.add(ConcreteDropout(Dense(32)))\n",
        "        # now model.output_shape == (None, 32)\n",
        "    ```\n",
        "    `ConcreteDropout` can be used with arbitrary layers which have 2D\n",
        "    kernels, not just `Dense`. However, Conv2D layers require different\n",
        "    weighing of the regulariser (use SpatialConcreteDropout instead).\n",
        "    # Arguments\n",
        "        layer: a layer instance.\n",
        "        weight_regularizer:\n",
        "            A positive number which satisfies\n",
        "                $weight_regularizer = l**2 / (\\tau * N)$\n",
        "            with prior lengthscale l, model precision $\\tau$ (inverse observation noise),\n",
        "            and N the number of instances in the dataset.\n",
        "            Note that kernel_regularizer is not needed.\n",
        "        dropout_regularizer:\n",
        "            A positive number which satisfies\n",
        "                $dropout_regularizer = 2 / (\\tau * N)$\n",
        "            with model precision $\\tau$ (inverse observation noise) and N the number of\n",
        "            instances in the dataset.\n",
        "            Note the relation between dropout_regularizer and weight_regularizer:\n",
        "                $weight_regularizer / dropout_regularizer = l**2 / 2$\n",
        "            with prior lengthscale l. Note also that the factor of two should be\n",
        "            ignored for cross-entropy loss, and used only for the eculedian loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer, weight_regularizer=1e-6, dropout_regularizer=1e-5,\n",
        "                 init_min=0.1, init_max=0.1, is_mc_dropout=True, **kwargs):\n",
        "        assert 'kernel_regularizer' not in kwargs\n",
        "        super(ConcreteDropout, self).__init__(**kwargs)\n",
        "        self.weight_regularizer = weight_regularizer\n",
        "        self.dropout_regularizer = dropout_regularizer\n",
        "        self.is_mc_dropout = is_mc_dropout\n",
        "        self.supports_masking = True\n",
        "        self.p_logit = None\n",
        "        self.p = None\n",
        "        self.init_min = np.log(init_min) - np.log(1. - init_min)\n",
        "        self.init_max = np.log(init_max) - np.log(1. - init_max)\n",
        "        self.layer = layer\n",
        "\n",
        "    def build(self, input_shape=None):\n",
        "        self.input_spec = InputSpec(shape=input_shape)\n",
        "        if not self.layer.built:\n",
        "            self.layer.build(input_shape)\n",
        "            self.layer.built = True\n",
        "        super(ConcreteDropout, self).build(input_shape=None)  # this is very weird.. we must call super before we add new losses\n",
        "\n",
        "        # initialise p\n",
        "        self.p_logit = self.layer.add_weight(name='p_logit',\n",
        "                                            shape=(1,),\n",
        "                                            initializer=initializers.RandomUniform(self.init_min, self.init_max),\n",
        "                                            trainable=True)\n",
        "        self.p = K.sigmoid(self.p_logit[0])\n",
        "\n",
        "        # initialise regulariser / prior KL term\n",
        "        assert len(input_shape) == 2, 'this wrapper only supports Dense layers'\n",
        "        input_dim = np.prod(input_shape[-1])  # we drop only last dim\n",
        "        weight = self.layer.kernel\n",
        "        kernel_regularizer = self.weight_regularizer * K.sum(K.square(weight)) / (1. - self.p)\n",
        "        dropout_regularizer = self.p * K.log(self.p)\n",
        "        dropout_regularizer += (1. - self.p) * K.log(1. - self.p)\n",
        "        dropout_regularizer *= self.dropout_regularizer * input_dim\n",
        "        regularizer = K.sum(kernel_regularizer + dropout_regularizer)\n",
        "        self.layer.add_loss(regularizer) # Eq 3 of the paper.\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return self.layer.compute_output_shape(input_shape)\n",
        "\n",
        "    def concrete_dropout(self, x):\n",
        "        '''\n",
        "        Concrete dropout - used at training time (gradients can be propagated)\n",
        "        :param x: input\n",
        "        :return:  approx. dropped out input\n",
        "        '''\n",
        "        eps = K.cast_to_floatx(K.epsilon())\n",
        "        temp = 0.1\n",
        "\n",
        "        unif_noise = K.random_uniform(shape=K.shape(x))\n",
        "        drop_prob = (\n",
        "            K.log(self.p + eps)\n",
        "            - K.log(1. - self.p + eps)\n",
        "            + K.log(unif_noise + eps)\n",
        "            - K.log(1. - unif_noise + eps)\n",
        "        )\n",
        "        drop_prob = K.sigmoid(drop_prob / temp)\n",
        "        random_tensor = 1. - drop_prob\n",
        "\n",
        "        retain_prob = 1. - self.p\n",
        "        x *= random_tensor\n",
        "        x /= retain_prob\n",
        "        return x\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if self.is_mc_dropout:\n",
        "            return self.layer.call(self.concrete_dropout(inputs))\n",
        "        else:\n",
        "            def relaxed_dropped_inputs():\n",
        "                return self.layer.call(self.concrete_dropout(inputs))\n",
        "            return K.in_train_phase(relaxed_dropped_inputs,\n",
        "                                    self.layer.call(inputs),\n",
        "                                    training=training)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEUsVZnAQMyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = 1 # dimension of data\n",
        "D = 1 # One mean and one var\n",
        "K_test = 20 # Number of MC samples\n",
        "nb_reps = 3\n",
        "batch_size = 20\n",
        "l = 1e-4 # length scale\n",
        "Q = 28*28\n",
        "nb_features = 512\n",
        "num_classes = 10\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS-gM-ZBQNht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e9f71685-db45-4335-fa0d-ef32c01a3759"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "print('x_train shape:', X_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "x_train shape: (60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3RU793AQQ5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjGX5W3FQSxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_model_1(nb_epoch, X, Y):\n",
        "    if K.backend() == 'tensorflow':\n",
        "        K.clear_session()\n",
        "    N = X.shape[0]\n",
        "    wd = l**2. / N\n",
        "    dd = 2. / N\n",
        "    print(N,wd,dd)\n",
        "    inp = Input(shape=(Q,))\n",
        "    x = inp\n",
        "    x = ConcreteDropout(Dense(nb_features, activation='relu'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "    x = ConcreteDropout(Dense(nb_features, activation='relu'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "    x = ConcreteDropout(Dense(nb_features, activation='relu'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "    out = ConcreteDropout(Dense(num_classes, activation='softmax'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "    # out = ConcreteDropout(Dense(), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "    # log_var = ConcreteDropout(Dense(D), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "    # out = Concatenate()([mean, log_var])\n",
        "    # out = merge([mean, log_var], mode='concat')\n",
        "    model = Model(inp, out)\n",
        "    \n",
        "    # def heteroscedastic_loss(true, pred):\n",
        "    #     mean = pred[:, :D]\n",
        "    #     log_var = pred[:, D:]\n",
        "    #     precision = K.exp(-log_var)\n",
        "    #     return K.sum(precision * (true - mean)**2. + log_var, -1)\n",
        "    \n",
        "    model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "    assert len(model.layers[1].trainable_weights) == 3  # kernel, bias, and dropout prob\n",
        "    assert len(model.losses) == 4  # a loss for each Concrete Dropout layer\n",
        "    hist = model.fit(X, Y, epochs=nb_epoch, batch_size=batch_size, verbose=1,validation_split=0.2)\n",
        "    loss = hist.history['loss'][-1]\n",
        "    return model, -0.5 * loss  # return ELBO up to const."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXfChXgPQWb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "e6b73859-1ebe-451c-994c-19a91381c692"
      },
      "source": [
        "nb_epoch = 20\n",
        "model, ELBO = fit_model_1(nb_epoch,X_train,y_train)\n",
        "MC_samples = np.array([model.predict(X_test) for _ in range(K_test)])\n",
        "ps = np.array([K.eval(layer.p) for layer in model.layers if hasattr(layer, 'p')])\n",
        "sys.stdout.flush()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 1.6666666666666667e-13 3.3333333333333335e-05\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/20\n",
            "48000/48000 [==============================] - 11s 231us/step - loss: 0.2263 - accuracy: 0.9229 - val_loss: 0.1301 - val_accuracy: 0.9532\n",
            "Epoch 2/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: 0.0904 - accuracy: 0.9660 - val_loss: 0.0858 - val_accuracy: 0.9670\n",
            "Epoch 3/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0571 - accuracy: 0.9756 - val_loss: 0.0790 - val_accuracy: 0.9702\n",
            "Epoch 4/20\n",
            "48000/48000 [==============================] - 9s 190us/step - loss: 0.0417 - accuracy: 0.9804 - val_loss: 0.0838 - val_accuracy: 0.9713\n",
            "Epoch 5/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0321 - accuracy: 0.9823 - val_loss: 0.0670 - val_accuracy: 0.9742\n",
            "Epoch 6/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: 0.0209 - accuracy: 0.9853 - val_loss: 0.0836 - val_accuracy: 0.9728\n",
            "Epoch 7/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0163 - accuracy: 0.9867 - val_loss: 0.0845 - val_accuracy: 0.9703\n",
            "Epoch 8/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: 0.0138 - accuracy: 0.9873 - val_loss: 0.0791 - val_accuracy: 0.9740\n",
            "Epoch 9/20\n",
            "48000/48000 [==============================] - 9s 194us/step - loss: 0.0061 - accuracy: 0.9895 - val_loss: 0.0922 - val_accuracy: 0.9755\n",
            "Epoch 10/20\n",
            "48000/48000 [==============================] - 9s 190us/step - loss: 0.0074 - accuracy: 0.9896 - val_loss: 0.0871 - val_accuracy: 0.9745\n",
            "Epoch 11/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: 0.0038 - accuracy: 0.9902 - val_loss: 0.0820 - val_accuracy: 0.9768\n",
            "Epoch 12/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: -5.9959e-04 - accuracy: 0.9916 - val_loss: 0.0908 - val_accuracy: 0.9750\n",
            "Epoch 13/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: -0.0020 - accuracy: 0.9926 - val_loss: 0.0992 - val_accuracy: 0.9758\n",
            "Epoch 14/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: -0.0035 - accuracy: 0.9926 - val_loss: 0.1034 - val_accuracy: 0.9762\n",
            "Epoch 15/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: -0.0038 - accuracy: 0.9932 - val_loss: 0.0828 - val_accuracy: 0.9794\n",
            "Epoch 16/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: -0.0024 - accuracy: 0.9927 - val_loss: 0.0959 - val_accuracy: 0.9756\n",
            "Epoch 17/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: -5.7859e-04 - accuracy: 0.9919 - val_loss: 0.0859 - val_accuracy: 0.9769\n",
            "Epoch 18/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: -0.0078 - accuracy: 0.9945 - val_loss: 0.1303 - val_accuracy: 0.9739\n",
            "Epoch 19/20\n",
            "48000/48000 [==============================] - 9s 188us/step - loss: -0.0064 - accuracy: 0.9942 - val_loss: 0.1216 - val_accuracy: 0.9768\n",
            "Epoch 20/20\n",
            "48000/48000 [==============================] - 9s 189us/step - loss: -0.0076 - accuracy: 0.9944 - val_loss: 0.1070 - val_accuracy: 0.9754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7PDQAzDQUte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "b6b359d8-fb94-4c13-d844-f5ed212eacc7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "concrete_dropout_1 (Concrete (None, 512)               401921    \n",
            "_________________________________________________________________\n",
            "concrete_dropout_2 (Concrete (None, 512)               262657    \n",
            "_________________________________________________________________\n",
            "concrete_dropout_3 (Concrete (None, 512)               262657    \n",
            "_________________________________________________________________\n",
            "concrete_dropout_4 (Concrete (None, 10)                5131      \n",
            "=================================================================\n",
            "Total params: 932,366\n",
            "Trainable params: 932,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtNakVniQYqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08a2036c-61b8-4893-b806-cade160c7e32"
      },
      "source": [
        "ps"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03927901, 0.0347207 , 0.23016612, 0.3527136 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBkVcMfvQam4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21b7d5a4-bffd-4439-9597-5795fd7ca989"
      },
      "source": [
        "loss, acc = model.evaluate(X_test,  y_test, verbose=0)\n",
        "acc"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9786999821662903"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciASieUVQcql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('model_conc_dropout.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaVJ-hb3QfHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "c0a3bb9a-b19b-4afd-feba-d6379cfcc437"
      },
      "source": [
        "# This segment doesnot work as a custom layer is not seriaizable in JSON format. Changes need to be done in the layer\n",
        "# itself to make compatible. It is better to just make a empty model and load weights.\n",
        "# from keras.models import model_from_json\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model_conc_dropout.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "\n",
        "# json_file = open('model_conc_dropout.json', 'r')\n",
        "# loaded_model_json = json_file.read()\n",
        "# json_file.close()\n",
        "# loaded_model = model_from_json(loaded_model_json)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b3a61ede552f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1042\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 140\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: ConcreteDropout"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNdNyhmfQhqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6711c4cb-f76f-40e0-efac-5f20d0ce1a74"
      },
      "source": [
        "N = 60000\n",
        "wd = l**2. / N\n",
        "dd = 2. / N\n",
        "print(N,wd,dd)\n",
        "inp = Input(shape=(Q,))\n",
        "x = inp\n",
        "x = ConcreteDropout(Dense(nb_features, activation='relu'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "x = ConcreteDropout(Dense(nb_features, activation='relu'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "x = ConcreteDropout(Dense(nb_features, activation='relu'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "out = ConcreteDropout(Dense(num_classes, activation='softmax'), weight_regularizer=wd, dropout_regularizer=dd)(x)\n",
        "test_model = Model(inp, out)\n",
        "\n",
        "test_model.load_weights('model_conc_dropout.h5')\n",
        "assert len(test_model.weights) == len(model.weights)\n",
        "for a, b in zip(test_model.weights, model.weights):\n",
        "  np.testing.assert_allclose(a.numpy(), b.numpy())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 1.6666666666666667e-13 3.3333333333333335e-05\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}